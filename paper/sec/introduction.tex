Cloud computing is expected to be one of the driving force of the
future economy~\citep{WPonMckinsey13}. Already, it has dramatically
changed the management of computing infrastructures. On one hand,
public cloud providers, such as Amazon EC2, allow companies to deploy
their services on large infrastructures with no up-front
cost~\citep{Buyya09:FGCS}. On the other hand, the flexibility offered
by cloud technologies themselves favors the adoption of private
clouds~\citep{Gulati11:HotCloud}, therefore, companies are converting
their own computing infrastructures into small, internally-managed
clouds.

One of the main advantages offered by cloud infrastructures is {\bf
  elasticity}. A company that wants to deploy a new service on the
cloud can rapidly provision the required computing resources,
automatically acquiring and releasing \acp{vm} as
required~\citep{Herbst13:ICAC}.  Elasticity can be of two
complementary types: vertical and horizontal. Vertical elasticity
consists in adding or removing resources (e.g., CPU cores) from an
existing \ac{vm}, while horizontal elasticity deals with changing the
number of \acp{vm} allocated to a specific service, adding a new
machine or removing an existing one.
%
Horizontal elasticity calls for the introduction of a specialized
component, called {\bf load-balancer}, that takes care of routing the
requests to one of the \acp{vm} composing the service. Load-balancing
techniques have been widely studied and
adopted~\citep{Barroso09,Lu11:PerfEval,Lin12:IGCC}.

One of the main issues with cloud computing infrastructures, however,
is {\bf robustness} to unexpected events. For example, flash-crowds
are sudden increases of end-users, that may increase the required
capacity by up to five times~\citep{Bodik10:SoCC}. Similarly, hardware
failures may temporarily reduce the capacity of the data-center, while
the failure is repaired~\citep{Barroso09}. Due to the large magnitude
and short duration of such events, it may be economically too costly
to provision enough hardware to properly deal with them. As a results,
unexpected events may lead to data-center overload, which translates
to unresponsive cloud applications, leading to dissatisfied end-users
and revenue loss.

Cloud applications therefore greatly benefit from
self-adaptation~\cite{SalehieSelfadaptive:TAAS}. One possible
adaptation is based on a paradigm called {\bf
  brownout}~\citep{cloudish-tr}. The main characteristic of cloud
brownout is adaptivity to obtain predictable performance despite
unexpected events like flash crowds. A brownout cloud application
adapts itself by reducing the amount of computation executed inside
the \ac{vm} to produce the response. In fact, some computations are
marked as mandatory --- for example, the display of the product
information in an e-commerce website --- while others are optional ---
for example, the display of recommendations of similar products.
Whenever a request is received, the application can choose to execute
or not the optional code based on the data-center conditions and on
its own optimization. Note that executing optional code directly
translates into a better service for the user and more revenues for
the company. This approach proved to be successful for dealing with
unexpected events. However, brownout applications were simply composed
by a single replica and running inside a single \ac{vm}.

In this paper, we extend the brownout paradigm to multiple \acp{vm},
developing a load-balancer that takes into account the replica
adaptation. This enables horizontal elasticity and makes applications
fault-tolerant by having several replicas. Existing, state-of-the-art
load-balancers forward requests based on the response-time of each
replica, which leads to inefficient decisions for brownout-compliant
applications, since such applications already keep their response-time
at a given setpoint (at the expense of reducing the amount of optional
content served). Specifically, a brownout-compliant load-balancer is
necessary, since by measuring response-time alone, it is not possible
to discriminate between a replica that is avoiding overload by not
executing the optional code and a replica that is not threatened with
overload executing all optional code, both achieving low response
times.  Therefore, existing load-balancing techniques that monitor
response times should be improved to migrate load away from replicas
not executing optional code.

Our challenge is to find a load-balancing methodology that maximizes
the amount of served optional content, provided that every replica
independentaly serves only an amount of optional code that allows it
to constrain the latency to be below a target value.

Our contribution is summarized as follows.
\begin{itemize}
\item We discuss load-balancing architectures and the requireed
  modifications to the classical structures that allow to deal with
  brownout-compliant applications and obtain predictability.
\item We propose two load-balancing policies that aim at maximizing
  the performance of brownout-compliant cloud applications, in terms
  of frequency of execution of the optional components, therefore
  maximizing the total revenue for the application provider.
\item We evaluate existing load-balancing strategies and compare them
  with the two proposed approaches, demonstrating the need for a
  brownout-aware load-balancer and proving that the proposed policies
  outperform existing techniques.
\end{itemize}
