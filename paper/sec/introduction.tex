Cloud computing is expected to be the driving force of future IT innovation~\cite{Gartner}. Instead of forcing businesses to make costly and risky investment in IT infrastructure, public clouds, such as Amazon EC2, allow such businesses to rent computing infrastructure as they grow, with no upfront costs~\cite{Buyya}. In fact, the model proved so successful, that companies are now converting their IT infrastructure to so-called private clouds, i.e., data-centers managed using cloud technologies, to improve IT efficiency~\cite{VMWare}.

In cloud computing, three roles can be distinguished: the {\bf\ac{ip}}, who owns and operates the cloud infrastructure, i.e., the physical hardware; the {\bf\ac{sp}}, who owns and operates cloud applications running on cloud infrastructures; the {\bf end-user}, who uses a cloud application through a network, commonly the Internet. Under the hood, cloud computing works by giving \acp{sp} the illusion of unrestricted (i.e., super-user) access to hardware, in the form of \acp{vm}. Besides simplifying certain tasks for \acp{sp} by hiding the complexity of the underlying infrastructure, \ac{vm} also increase the flexibility of the \ac{ip} by allowing an arbitrary mapping of physical hardware resources, such as CPU, memory and storage, to \acp{vm}.

A defining characteristic of clouds is {\bf elasticity}. It is defined as the ability of the \ac{sp} to rapidly and automatically acquire and release computing resources~\cite{ElasticityWhatItIs}. One can distinguish to complementary types of elasticity: vertical and horizontal. Vertical elasticity consists in adding or removing resources from an existing \ac{vm}, for example, by adding a virtual core or more memory. Horizontal elasticity consists in adding a new \ac{vm} to the pool of the \ac{sp}. Vertical elasticity is simpler to implement, as \ac{sp}'s cloud application can immediately take advantage of the new resources, but is limited to the capacity of a single physical machine, since a \ac{vm} cannot span multiple physical machines. In contrast, provided enough resources are available, horizontal elasticity is only limited to the total capacity of the data-center, however, it is more complex to implement: New replica of the application have to be launched inside the new \acp{vm}, replicas have to be kept synchronized and end-users have to be redirected to new \acp{vm}, using a specialized component called a {\bf load-balancer}. These techniques are well-known and have already been successfully applied in practice.

However, an existing issue with clouds is their robustness to unexpected events. For example, flash-crowds are sudden increases of end-users, that may increase the required capacity by up to 5 times~\cite{PeaksPaperThatMinaPresented}. Similarly, hardware failures may temporarily reduce the capacity of the data-center, while the failure is repaired. Due to the large magnitude and short duration of such events, it may be economically too costly to provision enough hardware to properly deal with them. As a results, unexpected events may lead to data-center overload, which translates to unresponsive cloud applications, leading to dissatisfied end-users and revenue loss.

In previous work~\cite{us}, we have proposed a cloud application development paradigm called {\bf brownout}. In essence, applications have optional code, that can be deactivated as necessary. While the execution of such code is desirable, as it improves end-user experience, its deactivation is preferred to overloading the data-center. For example, online stores display personalized recommendations of similar products. No doubt, such recommendations improve the experience of the end-user and the revenue of the \ac{sp}, however, due to their sophistication, they are also very resource demanding. Hence, the \ac{sp} desires to serve as many recommendations as possible, however, she would prefer to stop serving them instead of having an unresponsive application. Our contribution not only consisted in a general architecture for brownout-compliant applications, but also a controller to decide the probability of serving optional content as a function of the application's response time.

- previous contribution: brownout
- restricted to a single physical machine, vertical elasticity
- remaining issue: horizontal elasticity, redundancy through replication
- load balancer
- existing approaches use load or response-time, which is not okey for brownout-compliant applications
  - intuitively, since the application already controls its response-time at the expense of the number of optional requests served, existing load-balancing architectures and approaches cannot detect which replica is performing better.
- The contribution of this article is threefold:
  - We propose an architecture and a problem statement
  - We propose a control-theoretical load-balacing algorithm
  - We evaluate the approach

Problem statement
- architecture
- formalization
- question

