Load balancing has been explored exensively and different strategies
have different aims. For example, electricity based load balancing
proposes to reduce the amount of consumed electricity by directing the
requests to different replicas based on the electricity price
market~\cite{LoadBalancingForElectricity:TCC}.

In the software engineering context load balancing is often called
dynamic binding, so check the literature for that too.

In general it can be divided into different types. Static load
balancing refers to a fixed policy on a fixed system. Not only the
number of replicas is always the same but also the policy used to
select where to direct the traffic is always the same. This found many
applications early on, for example in load sharing on multiprocessor
systems~\cite{StaticLoadBalancing:TSE,StaticOptimal:ACM}. Among the
static load balancing techniques the most common are \textbf{random}
balancing, based on the random decisions. While this algorithm was
used pretty much everywhere, his utility is questionable, since it
does not take into account any factor in selecting the
replica. Another family of algorithms widely used in this case is the
\textbf{round robin} one, both in its plain version and in the
weighted derivations. A weighted round robin algorithm selects the
replica based on a priori knowledge of their capabilities, therefore
it is not indicated when the replicas itself are self-adaptive.
 
We are not interested in static load balancing, because we want to
account for variability, both in the number of replicas and in their
behavior. Our replicas, in fact can join the system later on ---
therefore taking into account autoscaling mechanism that are nowadays
popular in cloud computing --- and can be self-adaptive in nature, in
the sense that they can adjust their behavior to match specific
quality of service requirement like maximum or average latency
ones. 

We are interested in dynamic load balancing, where the choice of the
replica to be used is based on measurement of current quantities that
defines the system state --- for example, when the load balancer takes
into account the replica response times to decide where to send the
next request. Many approaches fall in this category. For example, in
old times, Stankovic proposed a Bayesian approach~\cite{Stankovic:TC}
to solve this problem. In his solution, an estimator of the queue
lenght per replica (in his case per processor because cloud computing
was not invened yet) is kept updated and the next job is sent to the
least congested replica. This algorithm is very unlikely to work in
our case because it has no knowledge of the adaptation that the single
replica is preforming, but we borrow from the idea of having the
replicas communicating some indicator of their behavior, and use it to
communicate the dimmer value. It would be nice to have this as a
comparison point, although it is from the 80s, we can simply feedback
the number of elements in the queue and see if that helps --- maybe we
would get similar results, although not by construction.

The \textbf{dynamic round robin} algorithm is similar to a weighted
round robin but the weights depend on the current status of the
server, for example on measurements of the current response times. A
currently widely implemented algorithm --- due to its simplicity ---
it to choose the fastest replica. However, also with replicas that are
not self-adaptive, this can cause severe congestion, since the current
response time does not always reflect the load of the machine and the
queue can saturate pretty fast. A less used strategy is based on
connection counts and select the replicas with the least
connections. This strategy works very well in environments where the
replicas have similar capabilities and the requests are
homogeneous. It might have problems if the requests are very different
from one another --- for example one serves a plain HTML page while
another requires a lot of database connections. A merge of the two has
been implemented, ranking the replicas based on a linear combination
of currently served requests and response times. This partially
overcomes the limitations induced by the two approaches but do not
take into account when the server is about to be
overloaded. Therefore, some \textbf{prediction} was introduced in this
method. Instead of ranking the replicas based on the linear
combination of the current metric, the difference between the past
metrics and the current ones was used, to distinguish which replicas
were improving and which were struggling. This is the solution
implemented by BIG-IP Local Traffic Manager.

\textcolor{blue}{\textit{\textbf{Martina:} In the ref folder there is
    a paper about a honey bees technique to do load
    balancing~\cite{BeesBased:ADAPTIVE}, based on the reward model
    that the bees use to produce honey. I personally think that this
    is not a very good way of doing load balancing but it is true that
    since this is a model based on reward, this might be a very good
    algorithm for comparison (since we can introduce the fact that
    recommendations are served therefore the request has a higher
    reward than a one without recommendations). Somebody interested in
    adapting this algorithm to our problem? In case nobody wants to do
    that, I'll do it.}}
