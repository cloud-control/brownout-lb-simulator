This section describe three different solutions for balancing the load
directed to self-adaptive brownout-compliant applications composed by
multiple replicas. The first two strategies are heuristic solution
that take into account the self-adaptivity of the replicas. The third
alternative is based on optimization theory, with the aim of providing
guarantees on the best possible behavior.

\subsection{Variational principle-based heuristic}

Our first solution is inspired by the predictive approach. In fact,
the core of the predictive solution is to examine the variation of the
involved quantities. While in its classical form, this solution relies
on variations of response times or connections per replica, our
solution is based on the how the control variables $\theta_i$ are
changing within each replica.

The approach determines the variation of the control variables
$\theta_i$ and correspondingly react. If the percentage of optional
content served is increasing, the replica is assumed to be less
loaded, and more traffic can be sent to it. On the contrary, when the
optional content diminish, the replica will receive less traffic, to
increase the control variable if possible.

The replica weights $w_i$ are initialized to $\frac{1}{n}$ where $n$
is the number of replicas. The load-balancer periodically updates the
values of the weights based on the values of $\theta_i$ received by
the replicas. At time $k$, denoting with $\Delta \theta_i (k)$ the
variation $\theta_i (k) - \theta_i (k-1)$, the solution computes a
potential weight $\tilde{w}_i(k+1)$ according to
\begin{equation}
  \tilde{w}_i(k+1) = w_i(k) \cdot 
\left[ 1 + \gamma_p \, \Delta \theta_i (k) + \gamma_i \, \theta_i (k) \right] ,
\label{eq:theta-diff}
\end{equation}
where $\gamma_p$ and $\gamma_i$ are constant gains, respectively
related to a proportional and an integral load-balancing action. As
calculated, $\tilde{w}_i$ values can be negative. This is clearly not
feasible, therefore negative values are truncated to a small but still
positive weight. Using a positive weight instead of zero allows us to
probe the replica and see whether it is favorably responding to new
incoming requests or not. Moreover, the computed values do not respect
the constraint that their sum is equal to 1, so they are then
re-scaled according to
\begin{equation}
  w_i (k) = \cfrac{\tilde{w}_i (k)}{\sum_i \tilde{w}_i (k)}.
\label{eq:theta-diff-rescale}
\end{equation}

Once $\gamma_p$ is fixed to a selected value, increasing the integral
gain $\gamma_i$ calls for a stronger action on the load-balancing
side, which means that the load-balancer would take decisions very
much influenced by the current values of $\theta_i$, therefore greatly
improving performance at the cost of a more nervous control action. On
the contrary, decreasing $\gamma_i$ would stabilize the control
signals, possibly losing performance due to a slower reaction
time. The choice of the integral gain allows to exploit the trade-off
between performance and robustness.

\subsection{Equality principle-based heuristic}

The second innovative policy presented here is based on the heuristic principle
that in the best conditions, every replica should have a similar
behavior, therefore the control variables $\theta_i$ should be as
close as possible to one another. This approach selects weights that
would encourage the control variables to converge to a single value.

The heuristic computes a potential weight $\tilde{w}_i(k+1)$ according
to
\begin{equation}
  \tilde{w}_i(k+1) = w_i(k) + \gamma_e e_i(k)
\label{eq:equal-thetas}
\end{equation}
where
$$e_i(k)=\left[ \theta_i (k) - \cfrac{\sum_j \theta_j (k) }{n} \right]$$
and $\gamma_e$ is a non-zero positive paramter of the algorithm which accounts
for how fast the algorithm should converge. The weights are simply modified
proportionally to the difference between the current control value and
the average control value set by the replicas. Clearly, the same
saturation and normalization described in Equation
\eqref{eq:theta-diff-rescale} has to be applied to the proposed
solution, to ensure that the sum of the weights is equal to one and
they have positive values --- i.e., that all the incoming traffic is
directed to the replicas and that each replica receives at least some
request.

By inserting the expression for $\tilde w_i$ from \eqref{eq:equal-thetas}
in the normalization equation \eqref{eq:theta-diff-rescale} we get the system
\begin{equation}
  w_i(k+1)=\cfrac{w_i(k)+\gamma_ee_i(k)}{\sum_jw_j(k)+\gamma_e\sum_je_j(k)}
\label{eq:weights}
\end{equation}
Since we normalized all weights $w_i(k)$ to sum to one ($\sum_jw_j(k)=1$), and
$$\sum_je_j(k)=\sum_j\left[\theta_j(k)-\frac{\sum_l\theta_l(k)}{n}\right]=0$$
we get that \eqref{eq:weights} in stationarity is
$$w_i(k)=w_i(k)+\gamma_ee_i(k)$$
and the only solution for this is that $e_i(k)=0$, all dimmers are equal in
stationarity.

\str{Comment on the parameter $\gamma_e$}

\subsection{Optimization based load-balancing}

The third approach presented here is to update the replica weights
based on the solution of an optimization problem, where the objective
is to maximize the quantity denoted by Equation~\eqref{eq:objective}.

In this solution, each replica is modeled as an $M/G/1$ queue with a
Processor Sharing (PS) discipline. The arrival clients are Markovian
(M) processes, the service times have a general (G) distribution and
each replica consists of a single server. According to the processor
sharing discipline, all clients are served immediately after their
arrival and share a fraction of the available computation power.

We use a general distribution for service times to account for the
brownout adaptation. For each replica $i$ we define $f_{S_i}$, the
probability density function for service times $S_i$, as
\begin{align}
  f_{S_i} (t) = (1 - \theta_i) \cdot \mu_i \cdot e^{-\mu_i \cdot t} +
  \theta_i \cdot M_i \cdot e^{-M_i \cdot t} ,
\label{eq:pdf-servicetimes}
\end{align}
where $t$ represents time, $\theta_i$ is the probability of activating
the optional components, $\mu_i$ denotes the service rate for requests
that do not have optional components enabled and $M_i$ is the service
rates for requests where the optional part is computed. Therefore, the
expression~\eqref{eq:pdf-servicetimes} is a mixture of two
exponentially distributed service times corresponding to serving all
clients with or without optional content. Although the replicas are
modeled as $M/G/1$ queues, the processor sharing discipline is
adopted. Therefore, the mean replicas response times can be computed
based on theoretical results on the $M/M/1$ queues, selecting
appropriate service rates. Each replica $i$ has an effective service
rate
\begin{equation}
  \mu_i^* = \left[ E[S_i] \right]^{-1} = \left[ \frac{1-\theta_i}{\mu_i}
    + \frac{\theta_i}{M_i} \right]^{-1} .
  \label{eq:effective-service-rate}
\end{equation}

It is possible to compute the value of the service rate that respects
the replica objective that the mean response times $t_i$ is equal to
the desired value $t_i^*$, that is given to the brownout-compliant
replica.
\begin{align}
  t_i & = \frac{1}{\mu_i^*-\lambda w_i} = t_i^* \\
  \Longrightarrow \mu_i^* & = \frac{1+t_i^*\lambda w_i}{t_i^*} 
  \label{eq:desired-service-rate}
\end{align}
Combining Equation~\eqref{eq:effective-service-rate} and
\eqref{eq:desired-service-rate}, it is possible compute the optimal
values of $\theta_i$ that would respect the response time
constraints. These values, $\theta_i^*$, are
\begin{equation}
  \theta_i^* = \frac{M_i \cdot \left( \mu_i t_i^* - 1 -\lambda w_i
      t_i^* \right)}{{\left( 1+\lambda w_i t_i^* \right) \cdot
      \left(\mu_i-M_i \right)}} = \frac{A_i - B_i w_i}{C_i + D_i w_i}.
  \label{eq:optimal-thetas}
\end{equation}

Recalling that $\theta_i$ is the probability of executing the optional
components when producing the response, the values $\theta_i^*$ should
be constrained to belong to the interval $[0, 1]$. Imposing this
condition provides the following inequalities.
\begin{equation}
  \frac{C_i-A_i}{B_i+D_i} \leq w_i \leq \frac{A_i}{B_i}
  \label{eq:constraints-optimal-thetas}
\end{equation}
Using these inequalities as constraints, it is possible to formally
state the optimization problem as
\begin{equation}
\begin{array}{rl}
  \max_{w_i} \;\;\; & J = \sum_i w_i \theta_i = \sum_i w_i  \frac{A_i - B_i w_i}{C_i + D_i w_i} \\
  \textnormal{s.t.} \;\;\; & \sum_i w_i = 1 \\
  & \max (0,\frac{C_i-A_i}{B_i+D_i}) \leq w_i \leq \frac{A_i}{B_i}
\end{array}
  \label{eq:optimization-problem}
\end{equation}

The objective function $J$ is concave in $w_i$ and the constraints are
linear. \str{Show these two.} Therefore the optimization problem is
concave. \str{Add a ``common language'' description of the
  optimization strategy. It basically does this and that.}

Notice that solving the optimization
problem~\eqref{eq:optimization-problem} guarantees that the best
possible solution is found, but however requires a lot of knowledge
about the single replica. In fact, while other solutions require to
know only the incoming traffic and the control variables for each
replica, the solution here relies on the knowledge of the service time
of requests with and without optional content $M_i$ and $\mu_i$ that
might not be available and could require additional computation to be
estimated correctly.
