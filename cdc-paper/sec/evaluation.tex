In this section we describe our experimental evaluation, discussing
the performance indicators used to compare different strategies, the
simulator developed and used to emulate the behavior of
brownout-compliant replicas driven by the load-balancer and our case
studies.

\subsection{Performance indicators}

Performance measures are necessary to objectively compare different
algorithms. While our first performance indicator is clearly defined
as the \textbf{percentage $\%_{oc}$} of the total requests served with
the optional content enabled, we also would like to introduce some
other performance metrics to compare the implemented load-balancing
techniques.

For this, we use the \textbf{user-perceived stability
  $\sigma_u$}~\cite{GeograficalSASO}. This metric refers to the
variation of performance as observed by the users, and it is measured
as the standard deviation of response times. Its purpose is to measure
the ability of the replicas to respond timely to the client
requests. The entire brownout framework aims at stabilizing the
response times, therefore it should achieve better user-perceived
stability, regardless of the presence of the load-balancer. However,
the load-balancing algorithm clearly influences the perceived
response times, therefore it is logical to check whether the newly
developed algorithms achieve a better perceived stability with respect
to the classical ones. Together with the value of the user-perceived
stability, we also report the \textbf{average response time $\mu_u$}
to distinguish between algorithms that achieve a low response time
with possibly high fluctuations from solutions that achieve a higher
but more stable response time.

\subsection{Simulator}

To test our load-balancing strategies, together with existing state of
the art solutions, we implemented a Python-based simulator for
brownout-compliant applications. In the simulator, it is easy to
plug-in new load-balancing algorithms. The simulator is based on the
concepts of \emph{Client}, \emph{Request}, \emph{LoadBalancer},
\emph{Replica} and \emph{Link}.

When a new client is defined, it can behave according to the open-loop
client model, where it simply issues a certain number of unrelated
requests (as it is true for clients that respect the Markovian
assumption), or according to the closed-loop
one~\cite{openvsclosed}. Closed-loop clients issue a request and wait
for the response, when they receive the response they think for some
time (in our simulations $1$s) and subsequently continue sending
another request to the application. While this second model is more
realistic, the first one is still useful to simulate the behavior of a
large number of clients. The simulator implements both models, to
allow for complete tests.

Requests are received by the load-balancer, that directs them towards
different replicas. The load-balancer can work on a per-request basis
or based on weights. The first case is used to simulate policies like
Round Robin, Random, Shortest Queue First and so on, that do not rely
on the concept of weights. The weighted load-balancer is used to
simulate the strategies proposed in this paper, as well as state of
the art solutions like the Weighted Round Robin.

Each replica simulates the computation necessary to serve the request
and chooses if it should be executed with or without the optional
components activated. If the optional content is served the service
time is a random number from a gaussian distribution with mean
$\phi_i$ and variance $0.01$, while if the optional content is not
served, the mean is $\psi_i$ and the variance is $0.001$. The
parameters $\phi_i$ and $\psi_i$ are specified when replicas are
created and can be changed during the execution. The service rate of
requests with the optional component $M_i = 1/\phi_i$ while for
serving only the mandatory part of the request the service rate is
$\mu_i = 1/\psi_i$. The replicas are also executing an internal
control loop to select their control variables, i.e., the probability
of executing the optional components. Details on the interal control
loops can be found in~\cite{cloudish-tr}. The replicas use Processor
Sharing to process the requests in the queue, meaning that each of the
$n$ active request will get $\frac{1}{n}$-th of the processing
capability of the replica.

Finally, there are network links connecting the load-balancer and the
replicas. These link are part of the simulator, to study the effect of
network delays in communicating the necessary feedback information for
the load-balancer execution.

The simulator receives as input a \emph{Scenario}, which describes
what can happen during the simulation. The scenario definition
supports the insertion of new clients and the removal of existing
ones. It also allows to turn on and off replicas at specific times
during the execution and to change the service times for every
replica, both for the optional components and for the mandatory
ones. This simulates a change in the amount of resources given to the
machine hosting the replica and it is based on the assumption that
these changes are unpredictable and can happen at the architecture
level, for example due to the cloud provider co-locating more
applications onto the same physical hardware, therefore reducing their
computation capability~\cite{Tomas13:CAC}.

With the scenarios, it is easy to simulate different working
conditions and to have a complete overview of the changes that might
happen during the load-balancing and replica execution. In the
following, we describe two experiments conducted to compare the
load-balancing strategies when subject to different execution
conditions.

\subsection{Reacting to client behavior}

The aim of the first test is to evaluate the performance of different
algorithms when new clients arrive and existing clients disconnect.

In the experiment the infrastructure is composed of four replicas. The
first replica is the fastest one and has $\phi_1 = 0.05$s (average
time to execute both the mandatory and the optional components) and
$\psi_1 = 0.005$s (average time to compute only the mandatory part of
the response). The second replica is slower, with $\phi_2 = 0.25$s and
$\psi_2 = 0.025$s. The third and fourth replicas are the slowest ones,
having $\phi_{3,4} = 0.5$s and $\psi_{3,4} = 0.05$s.

Clients adhere to the closed-loop model. $50$ clients are accessing
the system at time $0$s, and $10$ of them are removed after $200$s. At
time $400$s, $25$ more clients query the application and $25$ more
arrives again at $600$s. $40$ clients disconnect at time $800$s and
the simulation is ended at time $1000$s.

\begin{figure}[t!]
  \centering \input{img/clientchanges-full}
  \caption{Results of a simulation with four replicas and clients
    entering and leaving the system at different time instants. The
    left column shows the effective weights while the right column
    shows the control variables for each replica. The first replica is
    depicted in black solid lines, the second in blue dashed lines,
    the third in green dash-dotted lines, and the fourth in red dotted
    lines.}
    \vspace{-8mm}
\label{fig:clientchanges-full}
\end{figure}

\begin{figure}
\centering \input{img/clientchanges-boxplot}
  \vspace{-4mm}
\caption{Box plots of the maximum response time in all the replicas
  for every control interval. Each box depicts from the first quartile
  to the third. The red line shows the median; outliers are
  represented with red crosses while the black dots indicate the
  average value (also considering the outliers).}
  \vspace{-2mm}
\label{fig:clientchanges-boxplot}
\end{figure}

The right column in Figure~\ref{fig:clientchanges-full} shows the
control variable $\theta_i$ for each replica, while the left column
shows the effective weights $w_i$ that have been assigned by the
load-balancing strategies. Since solutions like the Round Robin do not
assign directly the weights, we decided to compute the effective
values that can be found after the load-balancing assignments. 

The algorithms are ordered based on the percentage $\%_{oc}$ of optional
content served, where the Equality Principle-Based Heuristic (EPBH)
achieves the best percentage overall, followed by the Variational
Principle-Based Heuristic (VPBH) and by the Optimization Based
Load-Balancer (OBLB).

For this scenario, the strategies that are aware of the adaptation at
the replica level achieve better results in terms of percentage of
optional content served. The Shortest Queue First (SQF) algorithm is
the only existing one capable of achieving similar (yet lower)
performance in terms of optional content delivered.

To analyze the effect of the load-balancing strategies on the replicas
response times, Figure~\ref{fig:clientchanges-boxplot} shows box plots
of the maximum response time experienced in intervals of time by the
replicas. The load-balancing strategies are ordered from left to right
based on the percentage of optional code $\%_{oc}$ achieved. As in
every box plot, the bottom line for each box represents the first
quartile, the top line the third and the red line is the median. The
red crosses depict the outliers. In addition to the classical box plot
information, the black dots depict for each algorithm the average
value of the maximum response time measured during the experiment, also
considering the outliers.

The box plots clearly show that all the solutions presented in this
paper achieve distributions that have outliers, as well as almost all
the literature ones. The only exception seems to be SQF, that achieves
predictable maximum response time, with a median that is just slightly
higher than the one achieved by VPBH. OBLB offers in this case a
compromise between optional content and the presence of outliers, that
are limited with respect to all the other solutions. EPBH offers the
highest percentage of optional content served, by sacrificing the
response time bound. From this additional information one can conclude that
the solutions presented in this paper should be tuned carefully if
response time requirements are hard. For example, for certain tasks,
users prefer a very response applications instead of many features,
hence the revenue of the application owner may be increased through
lower response times. \str{Previous sentence was unclear, please check
new text.}
Notice that the proposed heuristics
(EPBH and VPBH) have tunable parameters that can be used to exploit
the trade-off between response time bounds and optional content.

This case study features only a limited number of replicas. However,
we have conducted additional tests, also in more complex scenarios,
reporting results similar to the ones presented herein. In the next
section we test the effect of infrastructural changes to
load-balancing solutions and response times.

\subsection{Reacting to infrastructure resources}

In the second case study the architecture is composed of five
replicas. At time $0$s, the first replica has $\phi_1 = 0.07$s,
$\psi_1 = 0.001$s. The second and third replicas are medium and
$\phi_{2,3} = 0.14$s and $\psi_{2,3} = 0.002$s. The fourth and fifth
replicas are the slowest with $\phi_{4,5} = 0.7$s and $\psi_{4,5} =
0.01$s.

At time $250$s the amount of resources assigned to the first replica
is decreased, therefore $\phi_1 = 0.35$s and $\psi_1 = 0.005$s. At
time $500$s, the fifth replica receives more resources, achieving
$\phi_5 = 0.07$s and $\psi_5 = 0.001$s. The same happens at time $750$
to the fourth replica.

\begin{table}
\centering
\caption{Performance with variable infrastructure resources}
\label{tab:resourcechanges-performance}
\begin{tabular}{l c c c}
\hline
Algorithm   & $\%_{oc}$ & $\mu_u$ & $\sigma_u$ \\
\hline
OBLB        & $\mathbf{91.4\%}$ & $0.71$          & $0.89$ \\
EPBH        & $89.5\%$          & $1.06$          & $1.95$ \\
VPBH        & $87.7\%$          & $1.02$          & $1.90$ \\
SQF         & $83.3\%$          & $\mathbf{0.55}$ & $\mathbf{0.40}$ \\
RR          & $75,5\%$          & $1.11$          & $2.42$ \\
Random      & $72.9\%$          & $0.86$          & $2.23$ \\
2RC         & $72.2\%$          & $0.74$          & $1.64$ \\
FRF         & $70.4\%$          & $1.27$          & $2.03$ \\
Weighted-RR & $60.7\%$          & $0.90$          & $2.97$ \\
FRF-EWMA    & $51.4\%$          & $1.44$          & $3.41$ \\
Predictive  & $47.4\%$          & $1.66$          & $3.48$ \\
\hline
\end{tabular}
\vspace{-4mm}
\end{table}

Table~\ref{tab:resourcechanges-performance} reports the percentage
$\%_{oc}$, the average response time and the user-perceived stability
for the different algorithms. It should be noted again that the
our strategies obtain better optional content served at the expense of
slightly higher response times. However, the Optimization Based
Load-Balancer is capable of obtaining both low response times and high
percentage of optional content served. This is due to the amount of
information that it uses, since we assume that the computation times
for mandatory and optional part are known. The optimization-based
strategy is capable of reacting fast to changes and achieves
predictability in the application behavior. Again, if one does not
have all the necessary information available, it is possible to
implement strategies that would better exploit the trade-off between
bounded response time and optional content.
