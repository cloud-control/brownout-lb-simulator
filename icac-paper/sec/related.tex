Load-balancers are standard components of Internet-scale
services~\cite{WangOSDI}, allowing applications to achieve scalability
and resilience~\citep{Barroso09, Hamilton07:LISA,
  clusteredbalancing}. Many load-balancing policies have been
proposed, aiming at different optimizations, spanning from equalizing
processor load~\cite{Stankovic:TC} to managing memory
pools~\cite{PattersonMemoryLB,MemoryLBACC}, to specific optimizations
for iterative algorithms~\cite{BahiIterative}. Often load-balancing
policies consider web server systems~\cite{CLB,Cardellini2003} as a
target, where one of the most important result is to bound the maximum
response time that the clients are exposed
to~\cite{TC-Abdelzaher}. Load-balancing strategies can be guided by
many different purposes, for example
geografical~\cite{GeograficalSASO,geographicalwanbalancing} or driven
by the electricity price to reduce the datacenter operation 
cost~\cite{LoadBalancingForElectricity:TCC}. Cloud applications gave 
further boost to the research~\citep{Barroso09,Lu11:PerfEval,Lin12:IGCC}.

In general, load-balancing strategies can be either centralized or
distributed. A centralized solution is composed of a single
load-balancer that distributes the incoming load to a set of
replicas. On the contrary, in distributed solutions there are many
load-balancers connected to many replicas. In this paper we are
interested in how centralized solutions interact with self-adaptive
cloud applications. The novelty is given by the presence of two
different points of adaptation in the system, the behavior of the
infrastructure is modified both by the action of the load-balancer and
by the effect of the self-adaptivity introduced in cloud applications.

Load-balancing solutions can be divided into two different types:
static and dynamic. Static load-balancing refers to a fixed,
non-adaptive strategy to select a replica to direct traffic
to~\cite{StaticLoadBalancing:TSE,StaticOptimal:ACM}.  The most
commonly used techniques is based on selecting each replica in turn,
called \textbf{Round Robin (RR)}. It can be implemented either
deterministically, by storing the last selected replica, or
probabilistically, by picking a replica at random.  This technique can
further be improved by weighting the replica selection based on a
priori knowledge of their relative capacity, refered to as
\textbf{Weighted-RR}.  However, due to their non-adaptive nature, such
techniques cannot be applied to brownout-compliant load-balancing as
they do not take into account the inherent fluctuations of a cloud
environment, which leads to changing capabilities of replicas.

On the contrary, dynamic load-balancing is an adaptive technique, in
which the choice of the replica is based on measurements of the
current system.  One popular option is to choose the replica which had
the lowest response time in the past.  We refer to this algorithm as
\textbf{Fastest Replica First (FRF)} if the choice is based on the
last measured response time of each replica, and \textbf{FRF-EWMA} is
the choice is based on Exponentially Weighted Moving Average over the
past response times of each replica.  A variation of this algorithm is
\textbf{Two Random Choices (2RC)}~\cite{2RC}, that randomly chooses
two replicas and assigns the request to the fastest one, i.e., the one
with the lowest maximum response time.

Unfortunately, through experimental results, we were able to determine
that FRF, FRF-EWMA and 2RC are unsuitable for brownout
applications. They base their decision on response times alone, which
leads to inefficient decisions for brownout services. Indeed, such
services already keep their response-time at a given setpoint, at the
expense of reducing the amount of optional content served. Hence, by
measuring response-time alone, it is not possible to discriminate
between a replica that is avoiding overload by not executing the
optional code and a replica that is not threatened with overload
executing all optional code, both achieving low response times.

Another adopted strategy is based on the pending request count and
generally called \textbf{Shortest Queue First (SQF)}, where the
load-balancer tracks the pending requests and select the replicas with the
least amount of requests waiting for completion. This strategy pays off in architectures
where the replicas have similar capacities and the requests are
homogeneous. To account for non-homongeneity, Pao and Chen proposed a
load balancing solution using the remaining capacity of the replicas
to determine how the next request should be
managed~\cite{feedbackintensive}. The capacity is determined through a
combination of factors like the remaining available CPU and memory,
the network transmission and the current pending request count.  Other
approaches have been proposed that base their decision on remaining
capacity. However, due to the fact that brownout applications keep CPU
utilization around $60-70\%$ to prepare for possible request bursts,
deciding on remaining capacity alone is, just as with response time,
not an indicator of how well a brownout replica is performing.

A merge of the fastest replica and the pending request count approach was
implemented where the replicas are ranked based on a linear
combination of response times and number of routed requests. A
\textbf{Predictive} load balancer would rank the replicas based on the
difference between the past metrics and the current ones. A similar
solution is implemented in the BIG-IP Local Traffic
Manager~\cite{BIGIP}. One of the solutions proposed in this paper
borrows the idea of looking at the difference between the past
behavior and the current one, although our solution observes the
changes in the amount of optional code served and tries to maximize
the requests served enabling the full computation.

Dynamic solutions can be
control-theoretical~\cite{multipathctlb,comparisonstaticdynamic} and
also account for the cost of applying the control
action~\cite{costofcontrol} or for the load trend~\cite{CasolariSA}.
This is especially necessary when the load balancer also acts as a
resource allocator deciding not only where to route the current
request but also how much resources it would have to execute, 
like in~\cite{Ardagnaalltogether}. In these cases, the induced 
sudden lack of resources can result in poor performance. However, we 
are interested only in load-balancing solutions, since brownout applications
are already taking care of the potential lack of resources~\cite{cloudish-tr}.
